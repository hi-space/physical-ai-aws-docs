# Reasoning VLM (Vision-Language Model)

VLM(Vision-Language Model) 기반의 추론은 VLA(Vision-Language-Action)로 가는 중간 단계 또는 상위 두뇌 역할을 하도록 설계되었습니다. VLA가 아닌 추론 중심의 VLM으로 로봇을 제어하는 데에는 전략적 이유가 있습니다.

#### 1. '두뇌(Reason)'와 '손발(Action)'의 분리 (Modularity)

VLA 모델은 \[이미지 + 텍스트]를 입력받아 바로 \[로봇 팔의 좌표값(Action)]을 뱉어냅니다. 이는 편리하지만 단점이 있습니다.

* 문제점: 로봇의 하드웨어가 바뀔 때마다(예: 2족 보행 로봇 → 바퀴 달린 로봇) 모델 전체를 다시 학습시켜야 합니다.
* **Reasoning VLM의 접근**
  * **Reason (두뇌)**: 상황을 판단하고 "사과를 집어야 한다"는 **계획(Plan)**&#xC774;나 전략만 짭니다.
  * **Downstream Controller (손발)**: 실제 모터를 움직이는 제어는 기존의 로봇 제어 알고리즘이나 별도의 작은 정책 네트워크(Policy Network)가 담당합니다.
  * **장점**: 이렇게 하면 VLM 모델 하나로 휴머노이드, 로봇팔, 자율주행차 등 다양한 로봇에 범용적으로 적용할 수 있습니다.

#### 2. 물리적 상식(World Model)의 학습 효율성

로봇이 행동(Action)을 잘하려면 먼저 세상이 어떻게 돌아가는지(Physics)를 알아야 합니다.

* VLA 모델은 "행동 데이터"가 필요한데, 실제 로봇 행동 데이터는 수집하기가 매우 어렵고 비쌉니다.
* 반면, VLM은 인터넷상의 수많은 비디오 데이터를 통해 물리 법칙과 인과관계를 먼저 배울 수 있습니다. 행동 데이터 없이도 "컵을 놓으면 깨진다"는 것을 영상을 통해 학습하는 것이죠. 이렇게 학습된 '물리적 상식'을 바탕으로 추론하는 것이 훨씬 효율적입니다.

#### 3. 생각의 사슬 (Chain of Thought) 능력 극대화

VLA는 입력(영상) → 출력(행동)이 직관적으로 연결되지만, 복잡한 문제 해결에는 약할 수 있습니다.

* VLM은 텍스트 기반의 Chain of Thought(CoT) 추론을 수행합니다.
*   예를 들어, "방을 치워줘"라는 명령에 대해 바로 움직이는 게 아니라,

    1. "바닥에 옷이 있네."
    2. "옷은 옷장에 넣어야 해."
    3. "먼저 옷장 문을 열어야겠다."&#x20;

    라는 식의 논리적 단계를 텍스트/토큰 형태로 생성한 뒤, 이를 실행 단계로 넘기는 것이 복잡한 작업 수행에 유리합니다.

#### 4. 하이브리드 구조 (Hierarchical Approach)

최근 로봇 AI 트렌드는 계층적 구조입니다.

* **상위 레벨 (High-level)**: VLM이 "무엇을 할지(What to do)"와 "왜 해야 하는지(Why)"를 결정합니다.
* **하위 레벨 (Low-level)**: 실제 관절을 몇 도 꺾을지(How to move)는 제어 이론이나 별도의 VLA 파트가 담당합니다.

***

### 요약

범용성과 학습 효율성을 위해 순수 VLA(직접 제어) 대신 고수준의 추론과 계획을 담당하는 VLM을 활용할 수 있습니다. 이를 통해 어떤 형태의 로봇이든 "두뇌"로 탑재될 수 있게 만든 것입니다.

이러한 구조 덕분에 NVIDIA의 시뮬레이션 환경인 Isaac Lab이나 Jetson Thor 같은 하드웨어 위에서 실제 로봇의 '뇌'로 작동할 때 더 유연하게 쓰일 수 있습니다.
